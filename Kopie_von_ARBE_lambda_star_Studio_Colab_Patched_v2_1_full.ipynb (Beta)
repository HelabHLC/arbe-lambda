{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HelabHLC/arbe-lambda/blob/codex%2Fadd-test_lambda_star.py-with-dataset-validation/Kopie_von_ARBE_lambda_star_Studio_Colab_Patched_v2_1_full.ipynb%20(Beta)\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e8e10e5",
      "metadata": {
        "id": "6e8e10e5"
      },
      "source": [
        "# ARBE λ* Studio — Colab Patched v2.1\n",
        "Robustes Referenz-Laden (L,a,b[,name]), Spektral→λ*, Matching. share=True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6dea0cb8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dea0cb8",
        "outputId": "dadbd377-6e07-4c66-d57f-bbb007ac3d1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "\n",
        "# Installationen\n",
        "%pip -q install --upgrade pip\n",
        "%pip -q install \"gradio>=4.0.0\" plotly reportlab colour-science openpyxl\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7046c1ea",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "id": "7046c1ea",
        "outputId": "325ac2ce-d657-4d7c-86fb-c7a64e63fc85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://c3f48c32a11d465ae7.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://c3f48c32a11d465ae7.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "import io, os, re, math, zipfile, tempfile\n",
        "import numpy as np, pandas as pd\n",
        "import plotly.express as px\n",
        "import gradio as gr\n",
        "\n",
        "# ---------- Helpers ----------\n",
        "def read_file_bytes(file_or_path):\n",
        "    try:\n",
        "        return file_or_path.read()\n",
        "    except Exception:\n",
        "        path = None\n",
        "        if isinstance(file_or_path, str):\n",
        "            path = file_or_path\n",
        "        elif hasattr(file_or_path, \"name\"):\n",
        "            path = file_or_path.name\n",
        "        if path and os.path.exists(path):\n",
        "            with open(path, \"rb\") as fh:\n",
        "                return fh.read()\n",
        "        raise ValueError(\"Konnte Datei nicht lesen (Bytes oder Pfad erwartet).\")\n",
        "\n",
        "def read_csv_smart(byte_data):\n",
        "    sample = byte_data[:4096].decode('utf-8', errors='ignore')\n",
        "    decimal = ',' if re.search(r'\\d,\\d', sample) and not re.search(r'\\d\\.\\d', sample) else '.'\n",
        "    return pd.read_csv(io.BytesIO(byte_data), sep=None, engine=\"python\", decimal=decimal)\n",
        "\n",
        "# ---------- Spektral ----------\n",
        "def normalize_spectral_columns(df):\n",
        "    ren = {}\n",
        "    for orig in df.columns:\n",
        "        low = str(orig).strip().lower()\n",
        "        if low in ('sample','name','id','farbe','bezeichnung','color'): ren[orig] = 'sample'; continue\n",
        "        if low in ('l*','l'): ren[orig] = 'L'; continue\n",
        "        if low in ('a*','a'): ren[orig] = 'a'; continue\n",
        "        if low in ('b*','b'): ren[orig] = 'b'; continue\n",
        "        if low in ('wavelength','wellenl','wellenlaenge','nm','lambda','λ','lamda','wl'): ren[orig] = 'wavelength'; continue\n",
        "        if low in ('r','reflectance','value','y','refl','%r','intensity'): ren[orig] = 'R'; continue\n",
        "        m = re.match(r'^[rR][ _-]?(\\d{3})$', low)\n",
        "        if m: ren[orig] = m.group(1); continue\n",
        "        m = re.match(r'^(?:λ|lambda|nm[_-]?)?(\\d{3})$', low)\n",
        "        m2 = re.match(r'^(\\d{3})nm$', low)\n",
        "        if m: ren[orig] = m.group(1); continue\n",
        "        if m2: ren[orig] = m2.group(1); continue\n",
        "    return df.rename(columns=ren)\n",
        "\n",
        "def parse_csv_spectra(df):\n",
        "    df = normalize_spectral_columns(df)\n",
        "    if 'wavelength' in df.columns and 'R' in df.columns:\n",
        "        if 'sample' not in df.columns: df['sample'] = 'sample_1'\n",
        "        df['wavelength'] = df['wavelength'].astype(str).str.extract(r'(\\\\d{3})').astype(int)\n",
        "        R_series = pd.to_numeric(df['R'], errors='coerce')\n",
        "        if R_series.max() > 1.5: R_series = R_series/100.0\n",
        "        df['R'] = R_series.clip(0,1)\n",
        "        wide = df.pivot_table(index='sample', columns='wavelength', values='R', aggfunc='mean').reset_index().rename_axis(None, axis=1)\n",
        "        wls = sorted([int(c) for c in wide.columns if str(c).isdigit()])\n",
        "        return wide, wls\n",
        "    wl_cols = [c for c in df.columns if str(c).isdigit() and len(str(c))==3]\n",
        "    if not wl_cols: raise ValueError(\"Keine Spektralspalten gefunden.\")\n",
        "    if 'sample' not in df.columns:\n",
        "        first = df.columns[0]\n",
        "        if first not in wl_cols: df = df.rename(columns={first:'sample'})\n",
        "        else: df.insert(0,'sample',[f'sample_{i+1}' for i in range(len(df))])\n",
        "    for c in wl_cols:\n",
        "        vals = pd.to_numeric(df[c], errors='coerce')\n",
        "        if vals.max()>1.5: vals = vals/100.0\n",
        "        df[c] = vals.clip(0,1)\n",
        "    wls = sorted([int(c) for c in wl_cols])\n",
        "    keep = ['sample']+[str(w) for w in wls]\n",
        "    return df[keep], wls\n",
        "\n",
        "def parse_cgats(text):\n",
        "    rows=[]; wls=[]\n",
        "    for line in io.StringIO(text).read().splitlines():\n",
        "        s=line.strip()\n",
        "        if not s or s.startswith('COMMENT'): continue\n",
        "        parts=s.split()\n",
        "        if len(parts)>=2:\n",
        "            try:\n",
        "                wl=int(parts[0]);R=float(parts[1]); wls.append(wl); rows.append((wl,R))\n",
        "            except: pass\n",
        "    if not rows: raise ValueError(\"CGATS: keine Werte.\")\n",
        "    return pd.DataFrame([dict([('sample','sample_1')]+[(wl,R) for wl,R in rows])]), sorted(list(set([r[0] for r in rows])))\n",
        "\n",
        "def parse_cxf(xml_bytes):\n",
        "    import xml.etree.ElementTree as ET\n",
        "    txt = io.BytesIO(xml_bytes).read().decode('utf-8', errors='ignore')\n",
        "    ns={\"cc\":\"http://colorexchangeformat.com/CxF3-core\"}\n",
        "    try:\n",
        "        root=ET.fromstring(txt); rs=root.find(\".//cc:ReflectanceSpectrum\",ns)\n",
        "        if rs is not None:\n",
        "            start=380; step=10; name=\"sample_1\"\n",
        "            obj=root.find(\".//cc:Object\",ns);\n",
        "            if obj is not None and obj.get(\"Name\"): name=obj.get(\"Name\")\n",
        "            wr=root.find(\".//cc:WavelengthRange\",ns)\n",
        "            if wr is not None:\n",
        "                start=int(wr.get(\"StartWL\",start)); step=int(wr.get(\"Increment\",step))\n",
        "            vals=[float(t.replace(',','.')) for t in re.split(r\"[\\\\s,;]+\",(rs.text or '').strip()) if t]\n",
        "            wls=[start+i*step for i in range(len(vals))]\n",
        "            row={\"sample\":name};\n",
        "            for wl,v in zip(wls,vals): row[str(int(wl))]=v\n",
        "            return pd.DataFrame([row]), wls\n",
        "    except Exception: pass\n",
        "    wls=[]; Rs=[]\n",
        "    for m in re.finditer(r'<Wavelength[^>]*>(\\\\d+)</Wavelength>\\\\s*<Value[^>]*>([0-9\\\\.eE+-]+)</Value>', txt):\n",
        "        wls.append(int(m.group(1))); Rs.append(float(m.group(2)))\n",
        "    if not wls:\n",
        "        for m in re.finditer(r'<WaveLength[^>]*>(\\\\d+)</WaveLength>\\\\s*<Data[^>]*>([0-9\\\\.eE+-]+)</Data>', txt):\n",
        "            wls.append(int(m.group(1))); Rs.append(float(m.group(2)))\n",
        "    if not wls: raise ValueError(\"CxF: keine Werte.\")\n",
        "    return pd.DataFrame([dict([('sample','sample_1')]+list(zip(wls,Rs)))]), sorted(list(set(wls)))\n",
        "\n",
        "def get_illuminant_weights(wavelengths, name='EE'):\n",
        "    wl=np.array(wavelengths,dtype=float); w=np.ones_like(wl)\n",
        "    try:\n",
        "        import colour\n",
        "        if name in ['D50','D65','A']:\n",
        "            spd=colour.SDS_ILLUMINANTS[name]; w=np.array([spd.value(wi) for wi in wl])\n",
        "    except Exception: pass\n",
        "    return w\n",
        "\n",
        "def lambda_star_for_row(row, wls, illum='EE'):\n",
        "    R=np.array([float(row[str(w)]) for w in wls],dtype=float)\n",
        "    W=get_illuminant_weights(wls, illum)\n",
        "    num=(np.array(wls)*R*W).sum(); den=(R*W).sum()+1e-12\n",
        "    return float(num/den)\n",
        "\n",
        "def process_spectral_table(wide_df, wls, illum='EE'):\n",
        "    out=[]\n",
        "    for _,r in wide_df.iterrows():\n",
        "        out.append({'sample': r.get('sample','sample_1'), 'lambda_star': lambda_star_for_row(r,wls,illum)})\n",
        "    return pd.DataFrame(out)\n",
        "\n",
        "# ---------- Matching ----------\n",
        "def deltaE00(lab1, lab2):\n",
        "    L1,a1,b1=lab1; L2,a2,b2=lab2\n",
        "    avg_L=(L1+L2)/2.0\n",
        "    C1=math.hypot(a1,b1); C2=math.hypot(a2,b2); avg_C=(C1+C2)/2.0\n",
        "    G=0.5*(1-math.sqrt((avg_C**7)/((avg_C**7)+6103515625)))\n",
        "    a1p=(1+G)*a1; a2p=(1+G)*a2\n",
        "    C1p=math.hypot(a1p,b1); C2p=math.hypot(a2p,b2); avg_Cp=(C1p+C2p)/2.0\n",
        "    h1p=math.degrees(math.atan2(b1,a1p))%360.0; h2p=math.degrees(math.atan2(b2,a2p))%360.0\n",
        "    def dhp(h1,h2): d=h2-h1;\n",
        "    return d-360 if d>180 else (d+360 if d<-180 else d)\n",
        "\n",
        "    dLp=L2-L1; dCp=C2p-C1p; dh=dhp(h1p,h2p)\n",
        "    dHp=2*math.sqrt(C1p*C2p)*math.sin(math.radians(dh/2))\n",
        "    avg_hp=(h1p+h2p)/2.0 if abs(h1p-h2p)<=180 else (h1p+h2p+360)/2.0\n",
        "    T=(1-0.17*math.cos(math.radians(avg_hp-30))+0.24*math.cos(math.radians(2*avg_hp))+0.32*math.cos(math.radians(3*avg_hp+6))-0.20*math.cos(math.radians(4*avg_hp-63)))\n",
        "    SL=1+(0.015*(avg_L-50)**2)/math.sqrt(20+(avg_L-50)**2); SC=1+0.045*avg_Cp; SH=1+0.015*avg_Cp*T\n",
        "    Rt=-2*math.sqrt((avg_Cp**7)/((avg_Cp**7)+6103515625))*math.sin(math.radians(60*math.exp(-(((avg_hp-275)/25)**2))))\n",
        "    return float(math.sqrt((dLp/SL)**2+(dCp/SC)**2+(dHp/SH)**2+Rt*(dCp/SC)*(dHp/SH)))\n",
        "\n",
        "def nearest_neighbour(query_df, ref_df, method='DE00', threshold=None):\n",
        "    res=[]; R=ref_df[['L','a','b']].to_numpy(float)\n",
        "    for i,q in query_df.iterrows():\n",
        "        qv=np.array([q['L'],q['a'],q['b']],dtype=float)\n",
        "        dists=np.array([deltaE00(qv, rv) for rv in R]) if method!='DE76' else np.sqrt(((R-qv)**2).sum(axis=1))\n",
        "        idx=int(dists.argmin()); de=float(dists[idx])\n",
        "        if (threshold is None) or (de<=threshold):\n",
        "            name=ref_df.iloc[idx].get('name',f'ref_{idx}')\n",
        "            res.append({'query': q.get('name', f'q_{i}'),'L':q['L'],'a':q['a'],'b':q['b'],\n",
        "                        'match_name':name,'match_L':ref_df.iloc[idx]['L'],'match_a':ref_df.iloc[idx]['a'],'match_b':ref_df.iloc[idx]['b'],'deltaE':de,'method':method})\n",
        "    return pd.DataFrame(res)\n",
        "\n",
        "# ---------- UI ----------\n",
        "REF_TABLE=None\n",
        "\n",
        "def ui_load_reference(file):\n",
        "    global REF_TABLE\n",
        "    try:\n",
        "        raw=read_file_bytes(file)\n",
        "    except Exception as e:\n",
        "        return f\"Fehler beim Lesen der Datei: {e}\", None\n",
        "    try:\n",
        "        try: df=read_csv_smart(raw)\n",
        "        except Exception: df=pd.read_excel(io.BytesIO(raw))\n",
        "    except Exception as e:\n",
        "        return f\"Fehler beim Parsen (CSV/XLSX): {e}\", None\n",
        "\n",
        "    # Spaltenbereinigung (L groß halten)\n",
        "    df=df.rename(columns=lambda c: c.replace('*','') if isinstance(c,str) else c)\n",
        "    if 'Sample' in df.columns and 'name' not in df.columns: df=df.rename(columns={'Sample':'name'})\n",
        "    lowmap={str(c).strip().lower(): c for c in df.columns}\n",
        "    ren={}\n",
        "    if 'l' in lowmap: ren[lowmap['l']]='L'\n",
        "    if 'a' in lowmap: ren[lowmap['a']]='a'\n",
        "    if 'b' in lowmap: ren[lowmap['b']]='b'\n",
        "    if 'name' in lowmap: ren[lowmap['name']]='name'\n",
        "    if ren: df=df.rename(columns=ren)\n",
        "\n",
        "    low=[str(c).lower() for c in df.columns]\n",
        "    has_wl=any(re.fullmatch(r'(?:r_?)?\\\\d{3}', c) for c in low) or any(re.fullmatch(r'\\\\d{3}', c) for c in low)\n",
        "    has_lab=set(['l','a','b']).issubset(set(low))\n",
        "    if has_wl and not has_lab: return \"Diese Datei enthält Spektraldaten – bitte im Tab 'Spektral → λ*' laden.\", None\n",
        "\n",
        "    if not set(['L','a','b']).issubset(df.columns):\n",
        "        return f\"Referenz benötigt Spalten L,a,b[,name]. Gefunden: {list(df.columns)}\", None\n",
        "\n",
        "    REF_TABLE=df[['L','a','b']+(['name'] if 'name' in df.columns else [])].copy()\n",
        "    return f\"Referenz geladen: {len(REF_TABLE)} Zeilen.\", REF_TABLE.head(5)\n",
        "\n",
        "def ui_spectral_lambda(files, illuminant):\n",
        "    all_rows=[]\n",
        "    for f in files or []:\n",
        "        try:\n",
        "            name=getattr(f,\"orig_name\",None) or getattr(f,\"name\",\"uploaded\")\n",
        "            raw=read_file_bytes(f)\n",
        "            if str(name).lower().endswith('.csv'):\n",
        "                df=read_csv_smart(raw); wide,wls=parse_csv_spectra(df)\n",
        "            elif str(name).lower().endswith('.txt'):\n",
        "                txt=raw.decode('utf-8','ignore'); wide,wls=parse_cgats(txt)\n",
        "            elif str(name).lower().endswith(('.cxf','.xml')):\n",
        "                wide,wls=parse_cxf(raw)\n",
        "            else:\n",
        "                return None,None,f\"Nicht unterstützter Dateityp: {name}\",None\n",
        "            res=process_spectral_table(wide,wls,illum=illuminant); res['source']=name; all_rows.append(res)\n",
        "        except Exception as e:\n",
        "            all_rows.append(pd.DataFrame([{'sample':'ERROR','lambda_star':np.nan,'source':str(name),'error':str(e)}]))\n",
        "    if not all_rows: return None,None,\"Keine gültigen Dateien.\",None\n",
        "    out=pd.concat(all_rows,ignore_index=True)\n",
        "    fig=px.histogram(out.dropna(subset=['lambda_star']), x='lambda_star', nbins=60, title='Histogramm λ*')\n",
        "    if out['sample'].eq('ERROR').any():\n",
        "        err=out.loc[out['sample'].eq('ERROR'),['source','error']].drop_duplicates()\n",
        "        msg=\"Parser-Fehler bei einigen Dateien:\\\\n\"+err.to_string(index=False)\n",
        "    else:\n",
        "        msg=f\"{len(out)} Einträge verarbeitet.\"\n",
        "    return out, fig, msg, out.to_csv(index=False)\n",
        "\n",
        "def ui_match(query_file, method, threshold):\n",
        "    if REF_TABLE is None: return \"Bitte zuerst Referenz laden.\", None, None\n",
        "    if query_file is None: return \"Keine Query-Datei.\", None, None\n",
        "    try:\n",
        "        raw=read_file_bytes(query_file)\n",
        "    except Exception as e: return f\"Query nicht lesbar: {e}\", None, None\n",
        "    try:\n",
        "        try: q=read_csv_smart(raw)\n",
        "        except Exception: q=pd.read_excel(io.BytesIO(raw))\n",
        "    except Exception as e: return f\"Query nicht parsebar (CSV/XLSX): {e}\", None, None\n",
        "    q=q.rename(columns=lambda c: c.replace('*','') if isinstance(c,str) else c)\n",
        "    q=q.rename(columns={c: c.lower() for c in q.columns})\n",
        "    for need in ['l','a','b']:\n",
        "        if need not in q.columns: return f\"Spalte '{need}' fehlt in Query.\", None, None\n",
        "    q=q.rename(columns={'l':'L','a':'a','b':'b','name':'name'})\n",
        "    method_key='DE76' if method=='ΔE76' else 'DE00'\n",
        "    thr=threshold if (threshold and threshold>0) else None\n",
        "    res=nearest_neighbour(q[['L','a','b','name'] if 'name' in q.columns else ['L','a','b']], REF_TABLE, method=method_key, threshold=thr)\n",
        "    return f\"{len(res)} Matches.\", res, res.to_csv(index=False)\n",
        "\n",
        "with gr.Blocks(title=\"ARBE λ* Studio — Patched v2.1\") as demo:\n",
        "    gr.Markdown(\"## ARBE λ* Studio — Patched v2.1 (Colab)\")\n",
        "    with gr.Tab(\"Referenzen & Setup\"):\n",
        "        ref_file=gr.File(label=\"Referenz laden (CSV/XLSX: Spalten L,a,b[,name])\")\n",
        "        ref_status=gr.Textbox(label=\"Status\")\n",
        "        ref_preview=gr.Dataframe(label=\"Vorschau\")\n",
        "        ref_btn=gr.Button(\"Referenz laden\")\n",
        "        ref_btn.click(ui_load_reference, inputs=ref_file, outputs=[ref_status, ref_preview])\n",
        "    with gr.Tab(\"Spektral → λ*\"):\n",
        "        files=gr.Files(label=\"Spektraldateien (CSV/CGATS/CxF/ZIP)\")\n",
        "        illum=gr.Dropdown(choices=[\"D50\",\"D65\",\"A\",\"EE\"], value=\"EE\", label=\"Illuminant für λ*\")\n",
        "        run=gr.Button(\"λ* berechnen\")\n",
        "        out_table=gr.Dataframe(label=\"Ergebnisse λ*\"); fig=gr.Plot(label=\"Histogramm λ*\")\n",
        "        msg=gr.Textbox(label=\"Meldung\"); out_csv=gr.File(label=\"Download CSV\")\n",
        "        def _wrap_lambda(files, illum):\n",
        "            out,fig_,m,csv_txt=ui_spectral_lambda(files, illum)\n",
        "            csv_path=None\n",
        "            if csv_txt is not None:\n",
        "                tmp=tempfile.NamedTemporaryFile(delete=False, suffix=\".csv\")\n",
        "                tmp.write(csv_txt.encode(\"utf-8\")); tmp.flush(); tmp.close()\n",
        "                csv_path=tmp.name\n",
        "            return out, fig_, m, csv_path\n",
        "        run.click(_wrap_lambda, inputs=[files, illum], outputs=[out_table, fig, msg, out_csv])\n",
        "    with gr.Tab(\"Konvertieren & Suchen\"):\n",
        "        query_file=gr.File(label=\"Query CSV/XLSX (L,a,b[,name])\")\n",
        "        method=gr.Dropdown(choices=[\"ΔE00\",\"ΔE76\"], value=\"ΔE00\", label=\"Methode\")\n",
        "        thresh=gr.Slider(0,20,step=0.1,value=5.0,label=\"ΔE-Schwelle (optional)\")\n",
        "        btn=gr.Button(\"Matching starten\")\n",
        "        status=gr.Textbox(label=\"Status\"); res=gr.Dataframe(label=\"Matches\"); res_csv=gr.File(label=\"Download CSV\")\n",
        "        def _wrap_match(q,m,t):\n",
        "            s,df,csv=ui_match(q,m,t)\n",
        "            p=None\n",
        "            if csv is not None:\n",
        "                tmp=tempfile.NamedTemporaryFile(delete=False, suffix=\".csv\")\n",
        "                tmp.write(csv.encode(\"utf-8\")); tmp.flush(); tmp.close(); p=tmp.name\n",
        "            return s, df, p\n",
        "        btn.click(_wrap_match, inputs=[query_file, method, thresh], outputs=[status, res, res_csv])\n",
        "\n",
        "try:\n",
        "    import google.colab  # type: ignore\n",
        "    demo.launch(share=True)\n",
        "except Exception:\n",
        "    demo.launch()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neuer Abschnitt"
      ],
      "metadata": {
        "id": "7SMiCi99X8Ne"
      },
      "id": "7SMiCi99X8Ne"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}