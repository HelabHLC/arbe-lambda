{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39cc8773",
   "metadata": {},
   "source": [
    "\n",
    "# ARBE λ* Studio — **Final Version** (Gradio)\n",
    "All-in-one App für **Spektral→λ\\***, **Matching**, **Paletten**, **Harmonien**, **QA-Reports** und **Exporte**.\n",
    "\n",
    "> **Hinweis:** Für physikalisch korrekte Illuminanten-Gewichtung (D50/D65/A) und präzise Farbraumkonvertierungen nutzt das Notebook, sofern verfügbar, `colour-science`. Ohne `colour` werden **Equal-Energy**-Gewichtungen und **symbolische** sRGB-Previews verwendet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca3db3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Setup (Colab) ===\n",
    "import sys, os, io, json, math, zipfile, tempfile, shutil, base64, textwrap, pathlib, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Optional installs (uncomment in Colab if needed)\n",
    "try:\n",
    "    import gradio as gr\n",
    "except Exception:\n",
    "    !pip -q install gradio>=4.0.0\n",
    "    import gradio as gr\n",
    "\n",
    "# Plotting & reports\n",
    "try:\n",
    "    import plotly.express as px\n",
    "    import plotly.graph_objects as go\n",
    "except Exception:\n",
    "    !pip -q install plotly kaleido\n",
    "    import plotly.express as px\n",
    "    import plotly.graph_objects as go\n",
    "\n",
    "# PDF\n",
    "try:\n",
    "    from reportlab.lib.pagesizes import A4\n",
    "    from reportlab.pdfgen import canvas\n",
    "    from reportlab.lib.units import mm\n",
    "    from reportlab.lib.utils import ImageReader\n",
    "except Exception:\n",
    "    !pip -q install reportlab\n",
    "    from reportlab.lib.pagesizes import A4\n",
    "    from reportlab.pdfgen import canvas\n",
    "    from reportlab.lib.units import mm\n",
    "    from reportlab.lib.utils import ImageReader\n",
    "\n",
    "# Optional precise colour science\n",
    "COLOUR_AVAILABLE = False\n",
    "try:\n",
    "    import colour\n",
    "    COLOUR_AVAILABLE = True\n",
    "except Exception:\n",
    "    print(\"colour-science nicht installiert – Equal-Energy-Fallback aktiv (symbolisch).\")\n",
    "\n",
    "print(\"Versions:\", \"numpy\", np.__version__, \"pandas\", pd.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598286d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Utilities ===\n",
    "\n",
    "def clamp01(x):\n",
    "    return max(0.0, min(1.0, x))\n",
    "\n",
    "def srgb_to_rgb1(c):\n",
    "    # c in 0..255 -> 0..1\n",
    "    return np.asarray(c, dtype=float)/255.0\n",
    "\n",
    "def rgb1_to_srgb8(rgb):\n",
    "    return np.clip(np.round(np.asarray(rgb)*255).astype(int), 0, 255)\n",
    "\n",
    "# Basic sRGB <-> XYZ <-> Lab (approx., D65; Bradford to D50 only if colour available)\n",
    "# For accuracy, use colour-science if available\n",
    "def lab_to_srgb(lab, whitepoint=\"D50\"):\n",
    "    L,a,b = lab\n",
    "    if COLOUR_AVAILABLE:\n",
    "        wp = colour.CCS_ILLUMINANTS[\"CIE 1931 2 Degree Standard Observer\"][whitepoint]\n",
    "        xyz = colour.Lab_to_XYZ([L,a,b], illuminant=wp)\n",
    "        # Convert to sRGB (D65)\n",
    "        rgb = colour.XYZ_to_sRGB(xyz)\n",
    "        return np.clip(rgb, 0, 1)\n",
    "    else:\n",
    "        # simplified approximation via D65 matrix; not colour-accurate\n",
    "        # Use generic approximate conversion for preview\n",
    "        # Convert Lab(D50) -> XYZ(D50)\n",
    "        def f_inv(t):\n",
    "            d = 6/29\n",
    "            return t**3 if t> d else 3*d**2*(t-4/29)\n",
    "        Yn = 1.0; Xn = 0.9642; Zn = 0.8251  # D50 approx\n",
    "        fy = (L+16)/116; fx = fy + a/500; fz = fy - b/200\n",
    "        X = Xn * f_inv(fx); Y = Yn * f_inv(fy); Z = Zn * f_inv(fz)\n",
    "        # Bradford adapt D50->D65 (approx matrix)\n",
    "        M = np.array([[ 0.9555766, -0.0230393, 0.0631636],\n",
    "                      [-0.0282895,  1.0099416, 0.0210077],\n",
    "                      [ 0.0122982, -0.0204830, 1.3299098]])\n",
    "        X,Y,Z = M @ np.array([X,Y,Z])\n",
    "        # XYZ(D65) -> linear sRGB\n",
    "        M2 = np.array([[ 3.2406,-1.5372,-0.4986],\n",
    "                       [-0.9689, 1.8758, 0.0415],\n",
    "                       [ 0.0557,-0.2040, 1.0570]])\n",
    "        rgb_lin = M2 @ np.array([X,Y,Z])\n",
    "        # gamma companding\n",
    "        def compand(u):\n",
    "            return 12.92*u if u<=0.0031308 else 1.055*(u**(1/2.4))-0.055\n",
    "        rgb = np.array([compand(u) for u in rgb_lin])\n",
    "        return np.clip(rgb, 0, 1)\n",
    "\n",
    "def deltaE76(lab1, lab2):\n",
    "    d = np.array(lab1)-np.array(lab2)\n",
    "    return float(np.sqrt((d**2).sum()))\n",
    "\n",
    "def deltaE00(lab1, lab2):\n",
    "    # Implementation adapted from Sharma et al. 2005 (compact)\n",
    "    L1,a1,b1 = lab1; L2,a2,b2 = lab2\n",
    "    avg_L = (L1+L2)/2.0\n",
    "    C1 = math.hypot(a1,b1); C2 = math.hypot(a2,b2); avg_C = (C1+C2)/2.0\n",
    "    G = 0.5*(1 - math.sqrt((avg_C**7)/((avg_C**7)+6103515625)))  # 25^7\n",
    "    a1p = (1+G)*a1; a2p = (1+G)*a2\n",
    "    C1p = math.hypot(a1p,b1); C2p = math.hypot(a2p,b2); avg_Cp = (C1p+C2p)/2.0\n",
    "    h1p = math.degrees(math.atan2(b1,a1p)) % 360.0\n",
    "    h2p = math.degrees(math.atan2(b2,a2p)) % 360.0\n",
    "    def dhp(h1,h2):\n",
    "        d = h2-h1\n",
    "        if d>180: d -= 360\n",
    "        if d<-180: d += 360\n",
    "        return d\n",
    "    dLp = L2-L1\n",
    "    dCp = C2p-C1p\n",
    "    dh = dhp(h1p,h2p)\n",
    "    dHp = 2*math.sqrt(C1p*C2p)*math.sin(math.radians(dh/2))\n",
    "    avg_hp = (h1p+h2p)/2.0 if abs(h1p-h2p)<=180 else (h1p+h2p+360)/2.0\n",
    "    T = (1\n",
    "         - 0.17*math.cos(math.radians(avg_hp-30))\n",
    "         + 0.24*math.cos(math.radians(2*avg_hp))\n",
    "         + 0.32*math.cos(math.radians(3*avg_hp+6))\n",
    "         - 0.20*math.cos(math.radians(4*avg_hp-63)))\n",
    "    SL = 1 + (0.015*(avg_L-50)**2)/math.sqrt(20+(avg_L-50)**2)\n",
    "    SC = 1 + 0.045*avg_Cp\n",
    "    SH = 1 + 0.015*avg_Cp*T\n",
    "    Rt = -2*math.sqrt((avg_Cp**7)/((avg_Cp**7)+6103515625)) *          math.sin(math.radians(60*math.exp(-(((avg_hp-275)/25)**2))))\n",
    "    dE = math.sqrt((dLp/SL)**2 + (dCp/SC)**2 + (dHp/SH)**2 + Rt*(dCp/SC)*(dHp/SH))\n",
    "    return float(dE)\n",
    "\n",
    "def lch_to_lab(L, C, h_deg):\n",
    "    a = C * math.cos(math.radians(h_deg))\n",
    "    b = C * math.sin(math.radians(h_deg))\n",
    "    return (L, a, b)\n",
    "\n",
    "def lab_to_lch(L, a, b):\n",
    "    C = math.hypot(a,b)\n",
    "    h = (math.degrees(math.atan2(b,a)) + 360) % 360\n",
    "    return (L, C, h)\n",
    "\n",
    "def ensure_dataframe(obj):\n",
    "    if isinstance(obj, pd.DataFrame):\n",
    "        return obj\n",
    "    try:\n",
    "        return pd.read_csv(io.BytesIO(obj))  # uploaded bytes\n",
    "    except Exception:\n",
    "        try:\n",
    "            return pd.read_excel(io.BytesIO(obj))\n",
    "        except Exception:\n",
    "            raise ValueError(\"Ungültiges Tabellenformat (CSV/XLSX erwartet).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad445ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Spectral parsers & λ* ===\n",
    "def parse_csv_spectra(df):\n",
    "    # Expect wide or long: either columns 'wavelength' & 'R' + 'sample',\n",
    "    # or columns: 'sample', '380','390',...\n",
    "    wl_cols = [c for c in df.columns if re.match(r'^\\d{3}$', str(c))]\n",
    "    if 'wavelength' in df.columns and 'R' in df.columns:\n",
    "        # long: pivot to wide per sample\n",
    "        if 'sample' not in df.columns:\n",
    "            df['sample'] = 'sample_1'\n",
    "        wide = df.pivot_table(index='sample', columns='wavelength', values='R')\n",
    "        wide = wide.reset_index().rename_axis(None, axis=1)\n",
    "        return wide, sorted([int(c) for c in wide.columns if str(c).isdigit()])\n",
    "    elif len(wl_cols)>0:\n",
    "        wl = sorted([int(c) for c in wl_cols])\n",
    "        return df, wl\n",
    "    else:\n",
    "        raise ValueError(\"CSV: Keine spektralen Spalten gefunden.\")\n",
    "\n",
    "def parse_cgats(text):\n",
    "    rows = []\n",
    "    current = {}\n",
    "    wls = []\n",
    "    for line in io.StringIO(text).read().splitlines():\n",
    "        s = line.strip()\n",
    "        if not s or s.startswith('COMMENT'):\n",
    "            continue\n",
    "        parts = s.split()\n",
    "        if len(parts)>=2:\n",
    "            try:\n",
    "                wl = int(parts[0]); R = float(parts[1])\n",
    "                wls.append(wl); rows.append((wl,R))\n",
    "            except:\n",
    "                continue\n",
    "    if not rows:\n",
    "        raise ValueError(\"CGATS: Keine Werte erkannt.\")\n",
    "    # Construct single-sample wide table\n",
    "    wide = pd.DataFrame([dict([('sample','sample_1')]+[(wl,R) for wl,R in rows])])\n",
    "    return wide, sorted(list(set([r[0] for r in rows])))\n",
    "\n",
    "def parse_cxf(xml_bytes):\n",
    "    # Minimal CxF (best-effort): extract (wavelength, R) for first sample\n",
    "    txt = io.BytesIO(xml_bytes).read().decode('utf-8', errors='ignore')\n",
    "    wls, Rs = [], []\n",
    "    for m in re.finditer(r'<Wavelength[^>]*>(\\d+)</Wavelength>\\s*<Value[^>]*>([0-9\\.eE+-]+)</Value>', txt):\n",
    "        wls.append(int(m.group(1))); Rs.append(float(m.group(2)))\n",
    "    if not wls:\n",
    "        # alternative tag names\n",
    "        for m in re.finditer(r'<WaveLength[^>]*>(\\d+)</WaveLength>\\s*<Data[^>]*>([0-9\\.eE+-]+)</Data>', txt):\n",
    "            wls.append(int(m.group(1))); Rs.append(float(m.group(2)))\n",
    "    if not wls:\n",
    "        raise ValueError(\"CxF: Keine Werte erkannt.\")\n",
    "    wide = pd.DataFrame([dict([('sample','sample_1')]+list(zip(wls,Rs)))])\n",
    "    return wide, sorted(list(set(wls)))\n",
    "\n",
    "def get_illuminant_weights(wavelengths, name='EE'):\n",
    "    wl = np.array(wavelengths, dtype=float)\n",
    "    w = np.ones_like(wl)\n",
    "    if COLOUR_AVAILABLE and name in ['D50','D65','A']:\n",
    "        spd = colour.SDS_ILLUMINANTS[name]\n",
    "        w = np.array([spd.value(wi) for wi in wl])\n",
    "    return w\n",
    "\n",
    "def lambda_star_for_row(row, wls, illum='EE'):\n",
    "    R = np.array([float(row[str(w)]) for w in wls], dtype=float)\n",
    "    W = get_illuminant_weights(wls, illum)\n",
    "    num = (np.array(wls)*R*W).sum()\n",
    "    den = (R*W).sum() + 1e-12\n",
    "    return float(num/den)\n",
    "\n",
    "def process_spectral_table(wide_df, wls, illum='EE'):\n",
    "    out = []\n",
    "    for _,r in wide_df.iterrows():\n",
    "        lam = lambda_star_for_row(r, wls, illum)\n",
    "        out.append({'sample': r.get('sample','sample_1'), 'lambda_star': lam})\n",
    "    return pd.DataFrame(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d017fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Matching, palette, harmonies ===\n",
    "\n",
    "def nearest_neighbour(query_df, ref_df, method='DE00', threshold=None):\n",
    "    # expects columns L,a,b in both\n",
    "    res = []\n",
    "    R = ref_df[['L','a','b']].to_numpy(float)\n",
    "    for _,q in query_df.iterrows():\n",
    "        qv = np.array([q['L'], q['a'], q['b']], dtype=float)\n",
    "        # brute-force\n",
    "        if method=='DE76':\n",
    "            dists = np.sqrt(((R - qv)**2).sum(axis=1))\n",
    "        else:\n",
    "            dists = np.array([deltaE00(qv, rv) for rv in R])\n",
    "        idx = int(dists.argmin())\n",
    "        de = float(dists[idx])\n",
    "        if (threshold is None) or (de <= threshold):\n",
    "            name = ref_df.iloc[idx].get('name','ref_'+str(idx))\n",
    "            res.append({'query': q.get('name', f'q_{_}'),\n",
    "                        'L': q['L'],'a':q['a'],'b':q['b'],\n",
    "                        'match_name': name,\n",
    "                        'match_L': ref_df.iloc[idx]['L'],\n",
    "                        'match_a': ref_df.iloc[idx]['a'],\n",
    "                        'match_b': ref_df.iloc[idx]['b'],\n",
    "                        'deltaE': de,\n",
    "                        'method': method})\n",
    "    return pd.DataFrame(res)\n",
    "\n",
    "def kmeans_palette_from_image(img_arr, k=6, max_iter=25):\n",
    "    # Simple numpy k-means in RGB1 space\n",
    "    import numpy as np\n",
    "    data = img_arr.reshape(-1,3).astype(float)/255.0\n",
    "    # init: random samples\n",
    "    rng = np.random.default_rng(42)\n",
    "    cent = data[rng.choice(len(data), size=k, replace=False)]\n",
    "    for _ in range(max_iter):\n",
    "        d = ((data[:,None,:]-cent[None,:,:])**2).sum(axis=2)\n",
    "        lab = d.argmin(axis=1)\n",
    "        new_cent = np.array([data[lab==i].mean(axis=0) if np.any(lab==i) else cent[i] for i in range(k)])\n",
    "        if np.allclose(new_cent, cent): break\n",
    "        cent = new_cent\n",
    "    return (cent*255).astype(np.uint8)\n",
    "\n",
    "def lch_harmony(L,C,h, mode='analog', amount=30):\n",
    "    hs = []\n",
    "    if mode=='analog':\n",
    "        hs = [h-amount, h, h+amount]\n",
    "    elif mode=='komplement':\n",
    "        hs = [h, (h+180)%360]\n",
    "    elif mode=='triad':\n",
    "        hs = [h, (h+120)%360, (h+240)%360]\n",
    "    elif mode=='tetrad':\n",
    "        hs = [h, (h+90)%360, (h+180)%360, (h+270)%360]\n",
    "    return [lch_to_lab(L, C, hh%360) for hh in hs]\n",
    "\n",
    "def srgb_gamut_flag(lab):\n",
    "    rgb = lab_to_srgb(lab)\n",
    "    return bool(np.all((rgb>=0) & (rgb<=1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe6d845",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Exports ===\n",
    "\n",
    "def export_gpl(palette, name=\"ARBE_palette\"):\n",
    "    # palette: list of dicts {'name':..., 'r':0..255,'g':..,'b':..}\n",
    "    lines = [\"GIMP Palette\", \"Name: \"+name, \"Columns: 0\", \"#\"]\n",
    "    for p in palette:\n",
    "        lines.append(f\"{p['r']} {p['g']} {p['b']} {p.get('name','swatch')}\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "def export_aco(palette):\n",
    "    # Adobe Color Swatch v1 RGB\n",
    "    from struct import pack\n",
    "    # build v1 block\n",
    "    n = len(palette)\n",
    "    data = pack(\">H\", n)\n",
    "    for p in palette:\n",
    "        r,g,b = p['r'],p['g'],p['b']\n",
    "        data += pack(\">HHHHH\", 0, int(r/255*65535), int(g/255*65535), int(b/255*65535), 0)\n",
    "    # append v2 names\n",
    "    data += pack(\">H\", 2)  # version 2\n",
    "    data += pack(\">H\", n)\n",
    "    for p in palette:\n",
    "        r,g,b = p['r'],p['g'],p['b']\n",
    "        name = (p.get('name','swatch') + \"\\x00\").encode('utf-16be')\n",
    "        data += pack(\">HHHHH\", 0, int(r/255*65535), int(g/255*65535), int(b/255*65535), 0)\n",
    "        data += pack(\">H\", len(name)//2)\n",
    "        data += name\n",
    "    return data\n",
    "\n",
    "def export_ase(palette):\n",
    "    # Minimal ASE RGB (swatches only)\n",
    "    # palette: [{'name':str, 'r':0..255,'g':..,'b':..}]\n",
    "    # Build ASE format\n",
    "    import struct\n",
    "    def write_block_rgb(name, r,g,b):\n",
    "        nm = name.encode('utf-16be')\n",
    "        name_len = len(nm)//2 + 1\n",
    "        block = struct.pack(\">H\", 0x0001)  # color entry\n",
    "        payload = struct.pack(\">H\", name_len) + nm + b\"\\x00\\x00\"\n",
    "        payload += \"RGB \".encode(\"ascii\") + struct.pack(\">ffff\", r/255, g/255, b/255, 1.0)\n",
    "        payload += struct.pack(\">H\", 0)  # color type: global\n",
    "        block += struct.pack(\">I\", len(payload)) + payload\n",
    "        return block\n",
    "    header = b\"ASEF\" + struct.pack(\">HHI\", 1, 0, 0)  # version 1.0, count set later\n",
    "    blocks = []\n",
    "    for p in palette:\n",
    "        blocks.append(write_block_rgb(p.get('name','swatch'), p['r'],p['g'],p['b']))\n",
    "    count = len(blocks)\n",
    "    header = b\"ASEF\" + struct.pack(\">HHI\", 1, 0, count)\n",
    "    return header + b\"\".join(blocks)\n",
    "\n",
    "def make_qa_pdf(filepath, title, lambda_hist_png=None, table=None):\n",
    "    c = canvas.Canvas(filepath, pagesize=A4)\n",
    "    W,H = A4\n",
    "    c.setFont(\"Helvetica-Bold\", 16); c.drawString(30, H-40, title)\n",
    "    c.setFont(\"Helvetica\", 10)\n",
    "    y = H-70\n",
    "    if lambda_hist_png and os.path.exists(lambda_hist_png):\n",
    "        img = ImageReader(lambda_hist_png)\n",
    "        c.drawImage(img, 30, y-220, width=400, height=200, preserveAspectRatio=True, mask='auto')\n",
    "        y -= 230\n",
    "    if table is not None:\n",
    "        txt = c.beginText(30, y)\n",
    "        txt.textLine(\"Statistik:\")\n",
    "        for k,v in table.items():\n",
    "            txt.textLine(f\" - {k}: {v}\")\n",
    "        c.drawText(txt)\n",
    "    c.showPage(); c.save()\n",
    "    return filepath\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b64493",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Gradio UI ===\n",
    "\n",
    "REF_TABLE = None  # DataFrame with at least L,a,b[,name]\n",
    "THEME = \"light\"\n",
    "\n",
    "def ui_set_theme(theme):\n",
    "    global THEME\n",
    "    THEME = theme\n",
    "    return f\"Theme set to {theme}\"\n",
    "\n",
    "def ui_load_reference(file):\n",
    "    global REF_TABLE\n",
    "    if file is None: \n",
    "        return \"Keine Datei.\", None\n",
    "    content = file.read()\n",
    "    try:\n",
    "        df = pd.read_csv(io.BytesIO(content))\n",
    "    except Exception:\n",
    "        df = pd.read_excel(io.BytesIO(content))\n",
    "    # normalize columns\n",
    "    cols = {c.lower():c for c in df.columns}\n",
    "    rename = {}\n",
    "    for want in ['l','a','b','name','h','c','lch']:\n",
    "        if want in cols and cols[want]!=want:\n",
    "            rename[cols[want]] = want\n",
    "    df = df.rename(columns=rename)\n",
    "    REF_TABLE = df\n",
    "    return f\"Referenz geladen: {len(df)} Zeilen.\", df.head(5)\n",
    "\n",
    "def ui_spectral_lambda(files, illuminant):\n",
    "    all_rows = []\n",
    "    bins = []\n",
    "    for f in files or []:\n",
    "        name = f.name.lower()\n",
    "        data = f.read()\n",
    "        try:\n",
    "            if name.endswith('.csv'):\n",
    "                df = pd.read_csv(io.BytesIO(data))\n",
    "                wide, wls = parse_csv_spectra(df)\n",
    "            elif name.endswith('.txt'):\n",
    "                wide, wls = parse_cgats(data.decode('utf-8', errors='ignore'))\n",
    "            elif name.endswith('.cxf') or name.endswith('.xml'):\n",
    "                wide, wls = parse_cxf(data)\n",
    "            elif name.endswith('.zip'):\n",
    "                # unzip and try csv/txt/xml\n",
    "                z = zipfile.ZipFile(io.BytesIO(data))\n",
    "                for zi in z.infolist():\n",
    "                    if zi.filename.lower().endswith(('.csv','.txt','.cxf','.xml')):\n",
    "                        with z.open(zi) as fh:\n",
    "                            subdata = fh.read()\n",
    "                            # recurse minimalistic: only csv & txt & cxf\n",
    "                            if zi.filename.lower().endswith('.csv'):\n",
    "                                df = pd.read_csv(io.BytesIO(subdata))\n",
    "                                wide, wls = parse_csv_spectra(df)\n",
    "                            elif zi.filename.lower().endswith('.txt'):\n",
    "                                wide, wls = parse_cgats(subdata.decode('utf-8','ignore'))\n",
    "                            else:\n",
    "                                wide, wls = parse_cxf(subdata)\n",
    "                            res = process_spectral_table(wide, wls, illum=illuminant)\n",
    "                            res['source'] = zi.filename\n",
    "                            all_rows.append(res)\n",
    "                continue\n",
    "            else:\n",
    "                continue\n",
    "            res = process_spectral_table(wide, wls, illum=illuminant)\n",
    "            res['source'] = f.name\n",
    "            all_rows.append(res)\n",
    "        except Exception as e:\n",
    "            all_rows.append(pd.DataFrame([{'sample':'ERROR','lambda_star':np.nan,'source':f.name, 'error':str(e)}]))\n",
    "    if not all_rows:\n",
    "        return None, None, \"Keine gültigen Dateien.\", None\n",
    "    out = pd.concat(all_rows, ignore_index=True)\n",
    "    # Histogram\n",
    "    fig = px.histogram(out.dropna(subset=['lambda_star']), x='lambda_star', nbins=60, title='Histogramm λ*')\n",
    "    return out, fig, f\"{len(out)} Einträge verarbeitet.\", out.to_csv(index=False)\n",
    "\n",
    "def ui_match(query_file, method, threshold):\n",
    "    if REF_TABLE is None:\n",
    "        return \"Bitte zuerst Referenz laden.\", None, None\n",
    "    if query_file is None:\n",
    "        return \"Keine Query-Datei.\", None, None\n",
    "    q = ensure_dataframe(query_file.read())\n",
    "    # normalize\n",
    "    q = q.rename(columns={c: c.lower() for c in q.columns})\n",
    "    for need in ['l','a','b']:\n",
    "        if need not in q.columns:\n",
    "            return f\"Spalte '{need}' fehlt in Query.\", None, None\n",
    "    q = q.rename(columns={'l':'L','a':'a','b':'b','name':'name'})\n",
    "    ref = REF_TABLE.rename(columns={c:c if c in ['L','a','b','name'] else c.lower() for c in REF_TABLE.columns})\n",
    "    if not set(['L','a','b']).issubset(ref.columns):\n",
    "        return \"Referenz hat keine Spalten L,a,b.\", None, None\n",
    "    res = nearest_neighbour(q, ref[['L','a','b','name']], method=('DE76' if method=='ΔE76' else 'DE00'),\n",
    "                            threshold=(threshold if threshold and threshold>0 else None))\n",
    "    return f\"{len(res)} Matches.\", res, res.to_csv(index=False)\n",
    "\n",
    "def ui_palette(image, k):\n",
    "    if image is None:\n",
    "        return \"Kein Bild.\", None, None, None\n",
    "    pal = kmeans_palette_from_image(image, k=k)\n",
    "    rows = []\n",
    "    for i,(r,g,b) in enumerate(pal):\n",
    "        name = f\"swatch_{i+1}\"\n",
    "        rows.append({'name':name,'r':int(r),'g':int(g),'b':int(b)})\n",
    "    df = pd.DataFrame(rows)\n",
    "    gpl = export_gpl(rows, name=\"ARBE_palette\")\n",
    "    aco = export_aco(rows)\n",
    "    ase = export_ase(rows)\n",
    "    return f\"{len(rows)} Farben extrahiert.\", df, gpl, (aco, ase)\n",
    "\n",
    "def ui_harmonies(L, C, h, mode):\n",
    "    labs = lch_harmony(L,C,h, mode=mode)\n",
    "    rows = []\n",
    "    for i,lab in enumerate(labs):\n",
    "        in_gamut = srgb_gamut_flag(lab)\n",
    "        rgb = rgb1_to_srgb8(lab_to_srgb(lab))\n",
    "        rows.append({'name':f'h{ i+1 }','L':lab[0],'a':lab[1],'b':lab[2],\n",
    "                     'in_sRGB': in_gamut, 'r':int(rgb[0]),'g':int(rgb[1]),'b':int(rgb[2])})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "with gr.Blocks(title=\"ARBE λ* Studio — Final\") as demo:\n",
    "    gr.Markdown(\"## ARBE λ* Studio — Final Version\")\n",
    "    with gr.Row():\n",
    "        theme = gr.Dropdown(choices=[\"light\",\"dark\"], value=\"light\", label=\"Theme\")\n",
    "        theme.change(fn=ui_set_theme, inputs=theme, outputs=gr.Textbox(label=\"Status\"))\n",
    "    with gr.Tab(\"Referenzen & Setup\"):\n",
    "        ref_file = gr.File(label=\"Referenz laden (CSV/XLSX: Spalten L,a,b[,name])\")\n",
    "        ref_status = gr.Textbox(label=\"Status\")\n",
    "        ref_preview = gr.Dataframe(label=\"Vorschau\")\n",
    "        ref_btn = gr.Button(\"Referenz laden\")\n",
    "        ref_btn.click(ui_load_reference, inputs=ref_file, outputs=[ref_status, ref_preview])\n",
    "    with gr.Tab(\"Spektral → λ*\"):\n",
    "        files = gr.Files(label=\"Spektraldateien (CSV/CGATS/CxF/ZIP)\")\n",
    "        illum = gr.Dropdown(choices=[\"D50\",\"D65\",\"A\",\"EE\"], value=\"EE\", label=\"Illuminant für λ*\")\n",
    "        run = gr.Button(\"λ* berechnen\")\n",
    "        out_table = gr.Dataframe(label=\"Ergebnisse λ*\")\n",
    "        fig = gr.Plot(label=\"Histogramm λ*\")\n",
    "        msg = gr.Textbox(label=\"Meldung\")\n",
    "        out_csv = gr.File(label=\"Download CSV\")\n",
    "        def _wrap_lambda(files, illum):\n",
    "            out, fig_, m, csv_txt = ui_spectral_lambda(files, illum)\n",
    "            csv_path = None\n",
    "            if csv_txt is not None:\n",
    "                tmp = tempfile.NamedTemporaryFile(delete=False, suffix=\".csv\")\n",
    "                tmp.write(csv_txt.encode(\"utf-8\")); tmp.flush(); tmp.close()\n",
    "                csv_path = tmp.name\n",
    "            return out, fig_, m, csv_path\n",
    "        run.click(_wrap_lambda, inputs=[files, illum], outputs=[out_table, fig, msg, out_csv])\n",
    "    with gr.Tab(\"Konvertieren & Suchen\"):\n",
    "        query_file = gr.File(label=\"Query CSV/XLSX (L,a,b[,name])\")\n",
    "        method = gr.Dropdown(choices=[\"ΔE00\",\"ΔE76\"], value=\"ΔE00\", label=\"Methode\")\n",
    "        thresh = gr.Slider(0, 20, step=0.1, value=5.0, label=\"ΔE-Schwelle (optional)\")\n",
    "        btn = gr.Button(\"Matching starten\")\n",
    "        status = gr.Textbox(label=\"Status\")\n",
    "        res = gr.Dataframe(label=\"Matches\")\n",
    "        res_csv = gr.File(label=\"Download CSV\")\n",
    "        def _wrap_match(q, m, t):\n",
    "            s, df, csv = ui_match(q, m, t)\n",
    "            csv_path = None\n",
    "            if csv is not None:\n",
    "                tmp = tempfile.NamedTemporaryFile(delete=False, suffix=\".csv\")\n",
    "                tmp.write(csv.encode(\"utf-8\")); tmp.flush(); tmp.close()\n",
    "                csv_path = tmp.name\n",
    "            return s, df, csv_path\n",
    "        btn.click(_wrap_match, inputs=[query_file, method, thresh], outputs=[status, res, res_csv])\n",
    "    with gr.Tab(\"Bild → Palette & Exporte\"):\n",
    "        img = gr.Image(type=\"numpy\", label=\"Bild laden\")\n",
    "        k = gr.Slider(2, 12, step=1, value=6, label=\"Anzahl Farben\")\n",
    "        runp = gr.Button(\"Palette extrahieren\")\n",
    "        info = gr.Textbox(label=\"Status\")\n",
    "        pal = gr.Dataframe(label=\"Palette (RGB 0..255)\")\n",
    "        gpl = gr.Textbox(label=\"GPL (Text)\")\n",
    "        aco_file = gr.File(label=\"ACO\")\n",
    "        ase_file = gr.File(label=\"ASE\")\n",
    "        def _wrap_pal(image, k):\n",
    "            s, df, gpl_txt, (aco_bytes, ase_bytes) = ui_palette(image, k)\n",
    "            aco_path = tempfile.NamedTemporaryFile(delete=False, suffix=\".aco\"); open(aco_path.name,'wb').write(aco_bytes)\n",
    "            ase_path = tempfile.NamedTemporaryFile(delete=False, suffix=\".ase\"); open(ase_path.name,'wb').write(ase_bytes)\n",
    "            return s, df, gpl_txt, aco_path.name, ase_path.name\n",
    "        runp.click(_wrap_pal, inputs=[img, k], outputs=[info, pal, gpl, aco_file, ase_file])\n",
    "    with gr.Tab(\"Harmonien (LCh)\"):\n",
    "        L = gr.Slider(0, 100, value=60, label=\"L*\")\n",
    "        C = gr.Slider(0, 150, value=40, label=\"C\")\n",
    "        h = gr.Slider(0, 360, value=30, label=\"h°\")\n",
    "        mode = gr.Dropdown(choices=[\"analog\",\"komplement\",\"triad\",\"tetrad\"], value=\"analog\", label=\"Schema\")\n",
    "        go_btn = gr.Button(\"Erzeugen\")\n",
    "        res_tab = gr.Dataframe(label=\"Ergebnis (mit sRGB-Gamut-Flag)\")\n",
    "        go_btn.click(lambda L,C,h,mode: ui_harmonies(L,C,h,mode), inputs=[L,C,h,mode], outputs=res_tab)\n",
    "\n",
    "# Auto-launch in Colab\n",
    "try:\n",
    "    import google.colab  # type: ignore\n",
    "    demo.launch(share=False)\n",
    "except Exception:\n",
    "    print(\"Starte App lokal/Notebook: demo.launch() ausführen.\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
