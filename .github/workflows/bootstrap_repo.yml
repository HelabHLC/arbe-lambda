name: repo-bootstrap-arbe-lambda
on:
  workflow_dispatch:

permissions:
  contents: write
  pull-requests: write

jobs:
  bootstrap:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Git setup
        run: |
          git config user.name  "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"

      - name: Verify gh
        run: gh --version
        env: { GH_TOKEN: ${{ github.token }} }

      # PR 1 — Housekeeping
      - name: PR1 – Housekeeping (Ordner, Moves, .gitignore)
        env: { GH_TOKEN: ${{ github.token }} }
        run: |
          set -euo pipefail
          git fetch origin main
          git switch -c pr1-housekeeping origin/main || git switch -c pr1-housekeeping

          mkdir -p active/{data,docs,policy,releases,schema,tools,v3} archive "dev/sandbox"

          mv_if() { if [ -f "$1" ]; then git mv -k "$1" "$2"; fi }
          # Docs
          mv_if "prompt_generator_knowledgebase.md"                          "active/docs/"
          mv_if "prompt_generator_integration_kit_arbe_λ_36_genres_δe_00_λ_json.md" "active/docs/"
          # Policy
          if [ -f "atlas_only_policy (1).md" ]; then 
            mkdir -p active/policy; git mv -k "atlas_only_policy (1).md" "active/policy/atlas_only_policy.md"; 
          fi
          # Releases/Schema/Tools
          mv_if "release_arbe_lambda_v_2.md"              "active/releases/"
          mv_if "hybrid_compact.schema.json"               "active/schema/"
          mv_if "validate_arbe_lambda_dataset.py"          "active/tools/"
          mv_if "make_arbe_lambda_bundles.py"              "active/tools/"
          # Data
          mv_if "Hybrid_arbe_lambda_full_export_compact.csv" "active/data/"
          mv_if "arbe_lambda_star_v2_equal_energy_1nm(2).csv" "active/data/"
          # Dev/Archiv
          mv_if "arbe_lambda_gradio_app_vFinal.ipynb"      "dev/sandbox/"
          mv_if "release_template.md"                      "archive/"
          mv_if "arbe_lambda_KB_bundle_2025-09-21.zip"     "archive/"
          mv_if "arbe-lambda-v3.0.zip"                     "archive/"
          mv_if "swatch_generator_spectral→lab→s_rgb_arbe_λ_standard_template.py" "archive/"

          # .gitignore ergänzen
          touch .gitignore
          grep -qxF 'active/bundles/' .gitignore || echo 'active/bundles/' >> .gitignore
          grep -qxF '*.zip'            .gitignore || echo '*.zip'            >> .gitignore
          grep -qxF '*.tmp'            .gitignore || echo '*.tmp'            >> .gitignore
          grep -qxF '*.log'            .gitignore || echo '*.log'            >> .gitignore

          git add -A
          git commit -m "chore(repo): Struktur ordnen; Altlasten archiviert; v2 Dateien in /active"
          git push -u origin pr1-housekeeping

          PR1_URL=$(gh pr create --base main --head pr1-housekeeping \
            --title "chore(repo): Struktur ordnen, Altlasten archivieren, v2-Dateien nach /active verschoben" \
            --body "Räumt das Repo auf: klare /active-Struktur für v2, Altlasten ins /archive, Dev-Notebook nach /dev/sandbox. Vermeidet Dubletten & Versionskonflikte." \
            --json url --jq .url)
          echo "### PR1 – Housekeeping: ${PR1_URL}" >> "$GITHUB_STEP_SUMMARY"

      # PR 2 — CI
      - name: PR2 – CI (v2 validate & bundle workflow)
        env: { GH_TOKEN: ${{ github.token }} }
        run: |
          set -euo pipefail
          git fetch origin main
          git switch -c pr2-ci origin/main || git switch -c pr2-ci

          mkdir -p .github/workflows
          cat > .github/workflows/v2_validate_bundle.yml <<'YAML'
          name: v2-validate-and-bundle
          on:
            push: { branches: [ main ] }
            pull_request:
          jobs:
            build:
              runs-on: ubuntu-latest
              steps:
                - uses: actions/checkout@v4
                - uses: actions/setup-python@v5
                  with: { python-version: "3.11" }
                - name: Install deps
                  run: pip install pandas jsonschema
                - name: Validate v2 dataset
                  run: |
                    python active/tools/validate_arbe_lambda_dataset.py \
                      --csv active/data/Hybrid_arbe_lambda_full_export_compact.csv \
                      --schema active/schema/hybrid_compact.schema.json
                - name: Bundle v2 (self-test & pack)
                  run: |
                    python active/tools/make_arbe_lambda_bundles.py --self-test --out active/bundles
                    python - <<'PY'
                    import json,hashlib,os,zipfile,time
                    from pathlib import Path
                    base=Path("active"); out=base/"bundles"; out.mkdir(parents=True, exist_ok=True)
                    files=[]
                    for root,_,fns in os.walk(base):
                      if "/bundles" in root: continue
                      for fn in fns:
                        p=Path(root)/fn
                        h=hashlib.sha256(p.read_bytes()).hexdigest()
                        files.append({"path": str(p), "bytes": p.stat().st_size, "sha256": h})
                    man={"created": time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime()), "files": files}
                    (out/"manifest.json").write_text(json.dumps(man, indent=2), encoding="utf-8")
                    z=out/f"arbe_lambda_v2_bundle_{int(time.time())}.zip"
                    with zipfile.ZipFile(z,"w",zipfile.ZIP_DEFLATED) as zf:
                        zf.writestr("manifest.json",(out/"manifest.json").read_text())
                        [zf.write(f["path"], f["path"]) for f in files]
                    print("ZIP:", z)
                    PY
                - name: Upload bundle artifact
                  uses: actions/upload-artifact@v4
                  with:
                    name: v2-bundle
                    path: active/bundles/*.zip
          YAML

          git add .github/workflows/v2_validate_bundle.yml
          git commit -m "ci(v2): Validierung + Bundle als GitHub Actions Workflow"
          git push -u origin pr2-ci

          PR2_URL=$(gh pr create --base main --head pr2-ci \
            --title "ci(v2): Validierung + Bundle als GitHub Actions Workflow" \
            --body  "Automatisierte Schema-Validierung & reproduzierbares v2-Bundle (Manifest+ZIP) als CI-Artefakt." \
            --json url --jq .url)
          echo "### PR2 – CI: ${PR2_URL}" >> "$GITHUB_STEP_SUMMARY"

      # PR 3 — v3 Skeleton + README + DOI
      - name: PR3 – v3 Skeleton (UV+Vis 300–730, EE) + README/DOI
        env: { GH_TOKEN: ${{ github.token }} }
        run: |
          set -euo pipefail
          git fetch origin main
          git switch -c pr3-v3 origin/main || git switch -c pr3-v3

          mkdir -p active/v3/{schema,tools,docs,releases,data}

          # v3 Schema
          cat > active/v3/schema/arbe_lambda_v3_ee_compact.schema.json <<'JSON'
          {
            "$schema": "https://json-schema.org/draft/2020-12/schema",
            "title": "ARBE λ* v3 – Equal-Energy (UV+Vis 300–730 nm) compact schema",
            "type": "object",
            "properties": {
              "Sample": {"type": "string", "minLength": 1},
              "HEX": {"type": "string", "pattern": "^#?[0-9A-Fa-f]{6}$"},
              "λ*_V3_EE": {"type": "number", "minimum": 300, "maximum": 730},
              "Meta": {
                "type": "object",
                "properties": {
                  "range_nm": {"type": "array", "items": {"type": "number"}, "minItems": 2},
                  "step_nm": {"type": "number", "const": 1},
                  "illuminant": {"type": "string", "const": "EqualEnergy"},
                  "method": {"type": "string", "const": "Brent-Root on energetic difference"}
                },
                "required": ["range_nm", "step_nm", "illuminant", "method"],
                "additionalProperties": true
              }
            },
            "required": ["Sample", "HEX", "λ*_V3_EE"],
            "additionalProperties": true
          }
          JSON

          # v3 Brent Tool (kurz)
          cat > active/v3/tools/arbe_lambda_v3_ee_brent.py <<'PY'
          #!/usr/bin/env python3
          WL_MIN, WL_MAX = 300, 730
          def trapz(y, dx=1.0):
              return sum((y[i]+y[i+1])*0.5*dx for i in range(len(y)-1))
          def energetic_balance_diff(R, lam_star):
              idx = int(lam_star - WL_MIN); frac = lam_star - (WL_MIN + idx)
              ip = lambda a,b,t: a + (b-a)*t
              left = R[:idx+1];
              if idx+1 < len(R): left = left + [ip(R[idx], R[idx+1], frac)]
              right = ([ip(R[idx], R[idx+1], frac)] + R[idx+1:]) if idx+1 < len(R) else [R[-1]]
              A = trapz([1.0-v for v in left]); B = trapz(right); return A-B
          def brent_root(f,a,b,tol=1e-6,mi=200):
              fa,fb=f(a),f(b); c,fc=a,fa; d=e=b-a
              if fa*fb>0: raise ValueError('Root not bracketed')
              for _ in range(mi):
                  if fb==0: return b
                  if fa!=fc and fb!=fc:
                      s=(a*fb*fc/((fa-fb)*(fa-fc))+b*fa*fc/((fb-fa)*(fb-fc))+c*fa*fb/((fc-fa)*(fc-fb)))
                  else:
                      s=b-fb*(b-a)/(fb-fa)
                  if not(((3*a+b)/4<s<b) if a<b else (b<s<(3*a+b)/4)) or abs(s-b)>=abs(b-c)/2 or abs(b-c)<1e-12:
                      s=(a+b)/2; e=d=b-a
                  fs=f(s); c,fc=b,fb
                  if fa*fs<0: b,fb=s,fs
                  else: a,fa=s,fs
                  if abs(fa)<abs(fb): a,b=b,a; fa,fb=fb,fa
                  if abs(b-a)<tol: return b
              return b
          def lambda_star_ee(R):
              f=lambda lam: energetic_balance_diff(R, lam)
              a,b=WL_MIN,WL_MAX; pv=f(a); pl=a
              for lam in range(WL_MIN+1,WL_MAX+1):
                  v=f(lam)
                  if pv==0: return pl
                  if v==0 or pv*v<0: a,b=lam-1,lam; break
                  pl,pv=lam,v
              return brent_root(f,float(a),float(b))
          if __name__=='__main__':
              R=[0.05+0.0006*(w-300) for w in range(WL_MIN,WL_MAX+1)]
              print(f"λ*_V3_EE ≈ {lambda_star_ee(R):.3f} nm")
          PY
          chmod +x active/v3/tools/arbe_lambda_v3_ee_brent.py

          # Converter & Batch (Stubs, kurz gehalten)
          cat > active/v3/tools/convert_v2spectra_to_v3_stub.py <<'PY'
          #!/usr/bin/env python3
          import pandas as pd, math, argparse
          ap=argparse.ArgumentParser(); ap.add_argument('--in',dest='i',required=True); ap.add_argument('--out',dest='o',required=True); ap.add_argument('--qc',required=True); a=ap.parse_args()
          df=pd.read_csv(a.i); cols=[c for c in ['Sample','HEX','Name','Collection'] if c in df.columns]
          out=pd.DataFrame();
          [out.__setitem__(c,df[c]) for c in cols]
          for wl in range(300,731):
              c=f'R_{wl}'; out[c]=df[c] if c in df.columns else float('nan')
          qc=[]
          for _,r in out.iterrows():
              have=sum(1 for w in range(380,731) if not math.isnan(r[f'R_{w}']))
              miss=sum(1 for w in range(300,380) if math.isnan(r[f'R_{w}']))
              qc.append({'Sample': r.get('Sample',''), 'HEX': r.get('HEX',''), 'have_vis_380_730': have, 'missing_uv_300_379': miss, 'flag_uv_missing': 'YES' if miss>0 else 'NO'})
          pd.DataFrame(qc).to_csv(a.qc,index=False,encoding='utf-8-sig')
          out.to_csv(a.o,index=False,encoding='utf-8-sig')
          print('OK')
          PY
          chmod +x active/v3/tools/convert_v2spectra_to_v3_stub.py

          cat > active/v3/tools/batch_v3_lambda_and_deltaE.py <<'PY'
          #!/usr/bin/env python3
          import pandas as pd, argparse, math
          from arbe_lambda_v3_ee_brent import lambda_star_ee
          ap=argparse.ArgumentParser(); ap.add_argument('--v3',required=True); ap.add_argument('--out',required=True); ap.add_argument('--log',required=True); a=ap.parse_args()
          df=pd.read_csv(a.v3); res=[]; err=[]
          for i,r in df.iterrows():
              try:
                  R=[float(r[f'R_{w}']) for w in range(300,731)]
                  if any(pd.isna(v) for v in R): raise ValueError('Missing R_300..R_730')
                  lam=lambda_star_ee(R); res.append({'Sample': r.get('Sample',f'row_{i}'), 'λ*_V3_EE': lam, 'HEX': r.get('HEX','')})
              except Exception as e:
                  err.append({'row': i, 'error': str(e)})
          pd.DataFrame(res).to_csv(a.out,index=False,encoding='utf-8-sig')
          pd.DataFrame(err).to_csv(a.log,index=False,encoding='utf-8-sig')
          print(f"OK: {len(res)} | FAIL: {len(err)}")
          PY
          chmod +x active/v3/tools/batch_v3_lambda_and_deltaE.py

          # Docs
          cat > active/v3/docs/README_v3.md <<'MD'
          # ARBE λ* v3.0 – Equal-Energy (UV+Vis, 300–730 nm)
          Dieses Skeleton bringt Schema, Brent-Tool und Konverter. Daten (R_300..R_730 @1 nm) bitte in `active/v3/data/` ablegen.
          MD
          echo "# ARBE λ* v3 – Release Notes
          
- UV-Bereich 300–379 nm ergänzt
          
- Neuer Key: λ*_V3_EE" > active/v3/releases/RELEASE_NOTES_v3.md
          echo "(UV+Vis Placeholder)" > active/v3/data/MISSING_UV_DATA.md

          # README Badge/Status
          if [ -f README.md ]; then cp README.md README.md.bak; fi
          (echo "[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.17306436.svg)](https://doi.org/10.5281/zenodo.17306436)"; \
           echo; \
           echo "**Status**"; \
           echo "- **v2 (stable):** Vis 380–730 nm (EE + D50), Brent, QC & Bundles"; \
           echo "- **v3 (prep):** UV+Vis 300–730 nm (EE), neues Schema + Tools"; \
           echo; \
           if [ -f README.md.bak ]; then cat README.md.bak; fi) > README.md

          # Optional: CITATION.cff im Root
          cat > CITATION.cff <<'CFF'
          cff-version: 1.2.0
          message: "If you use ARBE λ*, please cite."
          title: "ARBE λ* v3.0 – Equal-Energy (UV+Vis, 300–730 nm)"
          identifiers:
            - type: doi
              value: 10.5281/zenodo.17306436
          CFF

          git add -A
          git commit -m "feat(v3): Skeleton (UV+Vis 300–730, EE) + Tools & Docs; README Badge/Status"
          git push -u origin pr3-v3

          PR3_URL=$(gh pr create --base main --head pr3-v3 \
            --title "feat(v3): Skeleton (UV+Vis 300–730, EE) + DOI-Link; Tools & Docs" \
            --body  "Bereitet v3 (UV+Vis, EE) vor: Schema, Brent-Tool, Converter/Batch und README-Badge. Daten folgen in active/v3/data/." \
            --json url --jq .url)
          echo "### PR3 – v3 Skeleton: ${PR3_URL}" >> "$GITHUB_STEP_SUMMARY"
